import 'dart:async';

import 'package:dart_openai/dart_openai.dart';
import 'package:flutter/foundation.dart';

import '../../domain/entities/chat_message.dart';
import '../../domain/providers/llm_provider.dart';
import '../../../../core/exceptions/app_exceptions.dart';

/// OpenAI LLM Providerå®ç°
///
/// ä½¿ç”¨dart_openaiåŒ…å®ç°ä¸OpenAI APIçš„äº¤äº’
class OpenAiLlmProvider extends LlmProvider {
  OpenAiLlmProvider(super.config) {
    _initializeOpenAI();
  }

  @override
  String get providerName => 'OpenAI';

  /// åˆå§‹åŒ–OpenAIé…ç½®
  void _initializeOpenAI() {
    OpenAI.apiKey = config.apiKey;

    if (config.baseUrl != null) {
      // ä¿®å¤baseUrlé‡å¤/v1çš„é—®é¢˜
      String cleanBaseUrl = config.baseUrl!.trim();
      
      // ç§»é™¤æœ«å°¾çš„æ–œæ 
      if (cleanBaseUrl.endsWith('/')) {
        cleanBaseUrl = cleanBaseUrl.substring(0, cleanBaseUrl.length - 1);
      }
      
      // å¦‚æœç”¨æˆ·å·²ç»é…ç½®äº†/v1ï¼Œåˆ™ç§»é™¤å®ƒï¼Œå› ä¸ºdart_openaiä¼šè‡ªåŠ¨æ·»åŠ 
      if (cleanBaseUrl.endsWith('/v1')) {
        cleanBaseUrl = cleanBaseUrl.substring(0, cleanBaseUrl.length - 3);
      }
      
      OpenAI.baseUrl = cleanBaseUrl;
      debugPrint('ğŸ”§ è®¾ç½®OpenAI baseUrl: $cleanBaseUrl (åŸå§‹: ${config.baseUrl})');
    }

    if (config.organizationId != null) {
      OpenAI.organization = config.organizationId;
    }
  }

  // ===== ç¼“å­˜æ¨¡å‹åˆ—è¡¨ï¼Œå‡å°‘é¢‘ç¹çš„ç½‘ç»œè¯·æ±‚ =====
  List<ModelInfo>? _cachedModels;
  DateTime? _cacheTime;
  static const Duration _cacheExpiry = Duration(hours: 1);

  @override
  Future<List<ModelInfo>> listModels() async {
    // å¦‚æœç¼“å­˜ä»ç„¶æœ‰æ•ˆï¼Œç›´æ¥è¿”å›ç¼“å­˜æ•°æ®
    final now = DateTime.now();
    if (_cachedModels != null &&
        _cacheTime != null &&
        now.difference(_cacheTime!) < _cacheExpiry) {
      return _cachedModels!;
    }

    try {
      // è°ƒç”¨ OpenAI åˆ—å‡ºæ¨¡å‹ API
      final models = await OpenAI.instance.model.list();

      // ä»…å–å¯ç”¨çš„æ¨¡å‹ idï¼Œç”Ÿæˆ ModelInfoï¼ˆå…¶å®ƒå­—æ®µç”¨é»˜è®¤ï¼‰
      final List<ModelInfo> result = models.map((m) {
        return ModelInfo(
          id: m.id,
          name: m.id, // é»˜è®¤æ˜¾ç¤ºåç§°ä¸ id ç›¸åŒï¼Œåç»­å¯ç¼–è¾‘
          type: ModelType.chat,
          supportsStreaming: true,
        );
      }).toList();

      // è‹¥ API è¿”å›ç©ºï¼Œé™çº§åˆ°é™æ€åˆ—è¡¨
      if (result.isEmpty) throw Exception('empty');

      // å†™å…¥ç¼“å­˜
      _cachedModels = result;
      _cacheTime = now;
      return result;
    } catch (_) {
      // è¿”å›é™æ€åˆ—è¡¨ä½œä¸ºå…œåº•ï¼Œå¹¶å†™å…¥ç¼“å­˜ï¼Œé¿å…è¿ç»­å¤±è´¥å¯¼è‡´é‡å¤è¯·æ±‚
      const fallback = <ModelInfo>[
        ModelInfo(
          id: 'gpt-3.5-turbo',
          name: 'gpt-3.5-turbo',
          type: ModelType.chat,
          supportsStreaming: true,
        ),
        ModelInfo(
          id: 'gpt-4o',
          name: 'gpt-4o',
          type: ModelType.chat,
          supportsStreaming: true,
        ),
        ModelInfo(
          id: 'text-embedding-3-small',
          name: 'text-embedding-3-small',
          type: ModelType.embedding,
          supportsStreaming: false,
        ),
      ];
      _cachedModels = fallback;
      _cacheTime = now;
      return fallback;
    }
  }

  @override
  Future<ChatResult> generateChat(
    List<ChatMessage> messages, {
    ChatOptions? options,
  }) async {
    try {
      final openAIMessages = _convertToOpenAIMessages(
        messages,
        options?.systemPrompt,
      );
      // é˜²å¾¡ï¼šå¦‚æœæ¶ˆæ¯ä½“ä¸ºç©ºï¼Œè¡¥ä¸€æ¡æœ€å°ç”¨æˆ·æ¶ˆæ¯ï¼Œé¿å…ä¸‹æ¸¸å…¼å®¹ç«¯ç‚¹æŠ¥ contents/messages ä¸ºç©º
      if (openAIMessages.isEmpty) {
        openAIMessages.add(
          OpenAIChatCompletionChoiceMessageModel(
            role: OpenAIChatMessageRole.user,
            content: [
              OpenAIChatCompletionChoiceMessageContentItemModel.text(
                options?.systemPrompt?.isNotEmpty == true
                    ? options!.systemPrompt!
                    : 'è¯·æ ¹æ®ç³»ç»ŸæŒ‡ä»¤ç»§ç»­å›ç­”ã€‚',
              ),
            ],
          ),
        );
      }
      final model = options?.model ?? config.defaultModel ?? 'gpt-3.5-turbo';

      final chatCompletion = await OpenAI.instance.chat.create(
        model: model,
        messages: openAIMessages,
        temperature: options?.temperature ?? 0.7,
        maxTokens: options?.maxTokens ?? 2048,
        // ä¸ä¼  topPï¼Œé¿å…ä¸éƒ¨åˆ†å…¼å®¹æ¨¡å‹ä¸å…¼å®¹
        frequencyPenalty: options?.frequencyPenalty ?? 0.0,
        presencePenalty: options?.presencePenalty ?? 0.0,
        stop: options?.stopSequences,
        // æš‚æ—¶ç§»é™¤å·¥å…·è°ƒç”¨åŠŸèƒ½
        // tools: options?.tools?.map(_convertToOpenAITool).toList(),
      );

      if (chatCompletion.choices.isEmpty) {
        throw ApiException('OpenAI APIè¿”å›äº†ç©ºçš„é€‰æ‹©åˆ—è¡¨');
      }

      final choice = chatCompletion.choices.first;
      final usage = chatCompletion.usage;

      // ä¿å­˜å®Œæ•´çš„åŸå§‹å†…å®¹
      final originalContent = choice.message.content?.isNotEmpty == true
          ? choice.message.content!.first.text ?? ''
          : '';

      debugPrint('ğŸ§  æ¥æ”¶å®Œæ•´å“åº”å†…å®¹: é•¿åº¦=${originalContent.length}');

      return ChatResult(
        content: originalContent, // ä¿å­˜å®Œæ•´å†…å®¹ï¼ŒUIå±‚é¢åˆ†ç¦»æ˜¾ç¤º
        model: model,
        tokenUsage: TokenUsage(
          inputTokens: usage.promptTokens,
          outputTokens: usage.completionTokens,
          totalTokens: usage.totalTokens,
        ),
        finishReason: _convertFinishReason(choice.finishReason),
        // æš‚æ—¶ç§»é™¤å·¥å…·è°ƒç”¨åŠŸèƒ½
        // toolCalls: choice.message.toolCalls?.map(_convertToolCall).toList(),
      );
    } catch (e) {
      throw _handleOpenAIError(e);
    }
  }

  @override
  Stream<StreamedChatResult> generateChatStream(
    List<ChatMessage> messages, {
    ChatOptions? options,
  }) async* {
    try {
      final openAIMessages = _convertToOpenAIMessages(
        messages,
        options?.systemPrompt,
      );
      if (openAIMessages.isEmpty) {
        openAIMessages.add(
          OpenAIChatCompletionChoiceMessageModel(
            role: OpenAIChatMessageRole.user,
            content: [
              OpenAIChatCompletionChoiceMessageContentItemModel.text(
                options?.systemPrompt?.isNotEmpty == true
                    ? options!.systemPrompt!
                    : 'è¯·æ ¹æ®ç³»ç»ŸæŒ‡ä»¤ç»§ç»­å›ç­”ã€‚',
              ),
            ],
          ),
        );
      }
      final model = options?.model ?? config.defaultModel ?? 'gpt-3.5-turbo';

      final stream = OpenAI.instance.chat.createStream(
        model: model,
        messages: openAIMessages,
        temperature: options?.temperature ?? 0.7,
        maxTokens: options?.maxTokens ?? 2048,
        // ä¸ä¼  topPï¼Œé¿å…ä¸éƒ¨åˆ†å…¼å®¹æ¨¡å‹ä¸å…¼å®¹
        frequencyPenalty: options?.frequencyPenalty ?? 0.0,
        presencePenalty: options?.presencePenalty ?? 0.0,
        stop: options?.stopSequences,
        // æš‚æ—¶ç§»é™¤å·¥å…·è°ƒç”¨åŠŸèƒ½
        // tools: options?.tools?.map(_convertToOpenAITool).toList(),
      );

      String accumulatedContent = ''; // ç´¯ç§¯å®Œæ•´åŸå§‹å†…å®¹

      await for (final chunk in stream) {
        if (chunk.choices.isEmpty) continue;

        final choice = chunk.choices.first;
        final delta = choice.delta;

        // å¤„ç†å†…å®¹å¢é‡
        if (delta.content != null && delta.content!.isNotEmpty) {
          final OpenAIChatCompletionChoiceMessageContentItemModel?
          firstContent = delta.content!.first;
          final String? deltaText = firstContent?.text;
          if (deltaText != null && deltaText.isNotEmpty) {
            accumulatedContent += deltaText;

            yield StreamedChatResult(
              delta: deltaText,
              content: accumulatedContent, // ä¿å­˜å®Œæ•´å†…å®¹
              isDone: false,
              model: model,
            );
          }
        }

        if (choice.finishReason != null) {
          debugPrint('ğŸ§  æµå¼å“åº”å®Œæˆ: å†…å®¹é•¿åº¦=${accumulatedContent.length}');

          yield StreamedChatResult(
            content: accumulatedContent, // ä¿å­˜å®Œæ•´å†…å®¹ï¼ŒUIå±‚é¢åˆ†ç¦»æ˜¾ç¤º
            isDone: true,
            model: model,
            tokenUsage: TokenUsage(
              inputTokens: 0, // æµå¼å“åº”ä¸­æ— æ³•å‡†ç¡®è·å–
              outputTokens: accumulatedContent.split(' ').length,
              totalTokens: accumulatedContent.split(' ').length,
            ),
            finishReason: _convertFinishReason(choice.finishReason),
          );
        }
      }
    } catch (e) {
      throw _handleOpenAIError(e);
    }
  }

  @override
  Future<EmbeddingResult> generateEmbeddings(List<String> texts) async {
    try {
      final model = config.defaultEmbeddingModel ?? 'text-embedding-3-small';

      debugPrint('ğŸ”— OpenAIåµŒå…¥è¯·æ±‚: æ¨¡å‹=$model, æ–‡æœ¬æ•°é‡=${texts.length}');
      debugPrint('ğŸŒ APIç«¯ç‚¹: ${config.baseUrl ?? 'https://api.openai.com'}');

      final embedding = await OpenAI.instance.embedding
          .create(model: model, input: texts)
          .timeout(
            const Duration(minutes: 2), // 2åˆ†é’Ÿè¶…æ—¶
            onTimeout: () {
              throw Exception('OpenAIåµŒå…¥è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIæœåŠ¡çŠ¶æ€');
            },
          );

      // æ£€æŸ¥å“åº”æ•°æ®æ˜¯å¦æœ‰æ•ˆ
      if (embedding.data.isEmpty) {
        throw Exception('OpenAI APIè¿”å›äº†ç©ºçš„åµŒå…¥æ•°æ®');
      }

      debugPrint('âœ… OpenAIåµŒå…¥è¯·æ±‚æˆåŠŸ: ç”Ÿæˆ${embedding.data.length}ä¸ªå‘é‡');

      // å®‰å…¨åœ°å¤„ç†åµŒå…¥æ•°æ®
      final embeddings = <List<double>>[];
      for (final item in embedding.data) {
        if (item.embeddings.isNotEmpty) {
          embeddings.add(item.embeddings);
        } else {
          debugPrint('âš ï¸ å‘ç°ç©ºçš„åµŒå…¥å‘é‡ï¼Œè·³è¿‡');
        }
      }

      if (embeddings.isEmpty) {
        throw Exception('æ‰€æœ‰åµŒå…¥å‘é‡éƒ½ä¸ºç©º');
      }

      return EmbeddingResult(
        embeddings: embeddings,
        model: model,
        tokenUsage: TokenUsage(
          inputTokens: embedding.usage?.promptTokens ?? 0,
          outputTokens: 0,
          totalTokens: embedding.usage?.totalTokens ?? 0,
        ),
      );
    } catch (e) {
      debugPrint('âŒ OpenAIåµŒå…¥è¯·æ±‚å¤±è´¥: $e');
      debugPrint('ğŸ” OpenAIé”™è¯¯è¯¦æƒ…: $e');

      // æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
      if (e.toString().contains('NoSuchMethodError')) {
        debugPrint('ğŸ’¡ è¿™å¯èƒ½æ˜¯APIå“åº”æ ¼å¼é—®é¢˜ï¼Œè¯·æ£€æŸ¥OpenAI APIç‰ˆæœ¬å…¼å®¹æ€§');
      }

      throw _handleOpenAIError(e);
    }
  }

  @override
  Future<bool> validateConfig() async {
    try {
      await OpenAI.instance.model.list();
      return true;
    } catch (e) {
      return false;
    }
  }

  @override
  int estimateTokens(String text) {
    // ç®€å•çš„tokenä¼°ç®—ï¼šå¤§çº¦4ä¸ªå­—ç¬¦ = 1ä¸ªtoken
    return (text.length / 4).ceil();
  }

  @override
  void dispose() {
    // OpenAI SDKä¸éœ€è¦ç‰¹æ®Šçš„æ¸…ç†
  }

  /// è½¬æ¢ä¸ºOpenAIæ¶ˆæ¯æ ¼å¼
  List<OpenAIChatCompletionChoiceMessageModel> _convertToOpenAIMessages(
    List<ChatMessage> messages,
    String? systemPrompt,
  ) {
    final openAIMessages = <OpenAIChatCompletionChoiceMessageModel>[];
    bool hasContentMessage = false; // æ˜¯å¦å­˜åœ¨è‡³å°‘ä¸€æ¡éç©ºå†…å®¹æ¶ˆæ¯

    // æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆæ”¾åœ¨æœ€å‰ï¼‰
    if (systemPrompt != null && systemPrompt.isNotEmpty) {
      openAIMessages.add(
        OpenAIChatCompletionChoiceMessageModel(
          role: OpenAIChatMessageRole.system,
          content: [
            OpenAIChatCompletionChoiceMessageContentItemModel.text(
              systemPrompt,
            ),
          ],
        ),
      );
    }

    // è½¬æ¢èŠå¤©æ¶ˆæ¯ï¼ˆè·³è¿‡ç©ºå†…å®¹é¡¹ï¼‰
    for (final message in messages) {
      final contentItems =
          <OpenAIChatCompletionChoiceMessageContentItemModel>[];

      // æ·»åŠ æ–‡æœ¬å†…å®¹
      if (message.content.isNotEmpty) {
        contentItems.add(
          OpenAIChatCompletionChoiceMessageContentItemModel.text(
            message.content,
          ),
        );
      }

      // æ·»åŠ å›¾ç‰‡å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
      if (message.imageUrls.isNotEmpty) {
        for (final imageUrl in message.imageUrls) {
          // æ£€æŸ¥æ˜¯å¦æ˜¯base64æ ¼å¼çš„å›¾ç‰‡
          if (imageUrl.startsWith('data:image/')) {
            contentItems.add(
              OpenAIChatCompletionChoiceMessageContentItemModel.imageUrl(
                imageUrl,
              ),
            );
          } else if (imageUrl.startsWith('file://')) {
            // å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„ï¼Œéœ€è¦è½¬æ¢ä¸ºbase64
            // è¿™é‡Œæš‚æ—¶è·³è¿‡ï¼Œå› ä¸ºéœ€è¦å¼‚æ­¥è¯»å–æ–‡ä»¶
            debugPrint('âš ï¸ æ–‡ä»¶è·¯å¾„æ ¼å¼çš„å›¾ç‰‡æš‚ä¸æ”¯æŒ: $imageUrl');
          } else {
            // å‡è®¾æ˜¯URLæˆ–base64å­—ç¬¦ä¸²
            contentItems.add(
              OpenAIChatCompletionChoiceMessageContentItemModel.imageUrl(
                imageUrl,
              ),
            );
          }
        }
      }

      // ä»…åœ¨å­˜åœ¨å†…å®¹é¡¹æ—¶æ‰è¿½åŠ ï¼Œé¿å…ç©º content è§¦å‘ä¸‹æ¸¸é”™è¯¯
      if (contentItems.isNotEmpty) {
        hasContentMessage = true;
        openAIMessages.add(
          OpenAIChatCompletionChoiceMessageModel(
            role: message.isFromUser
                ? OpenAIChatMessageRole.user
                : OpenAIChatMessageRole.assistant,
            content: contentItems,
          ),
        );
      }
    }

    // è‹¥æœ€ç»ˆæ²¡æœ‰ä»»ä½•æœ‰æ•ˆå†…å®¹æ¶ˆæ¯ï¼Œè¡¥ä¸€æ¡æœ€å°ç”¨æˆ·æ¶ˆæ¯ä½œä¸ºå…œåº•
    if (!hasContentMessage) {
      openAIMessages.add(
        OpenAIChatCompletionChoiceMessageModel(
          role: OpenAIChatMessageRole.user,
          content: [
            OpenAIChatCompletionChoiceMessageContentItemModel.text(
              (systemPrompt != null && systemPrompt.isNotEmpty)
                  ? systemPrompt
                  : 'è¯·æ ¹æ®ç³»ç»ŸæŒ‡ä»¤ç»§ç»­å›ç­”ã€‚',
            ),
          ],
        ),
      );
    }

    // å¼ºåŒ–ä¿éšœï¼šç¡®ä¿æœ€åä¸€æ¡æ˜¯å½“å‰ç”¨æˆ·è¾“å…¥ï¼ˆéƒ¨åˆ†ç½‘å…³æ›´ä¾èµ–æœ€åä¸€æ¡ user å†…å®¹ï¼‰
    final ChatMessage lastUserInput = messages.lastWhere(
      (m) => m.isFromUser,
      orElse: () => ChatMessage(
        id: 'fallback',
        content: '',
        isFromUser: true,
        timestamp: DateTime.now(),
        chatSessionId: 'fallback',
      ),
    );
    final latestUserText = (lastUserInput.content).trim();
    if (latestUserText.isNotEmpty) {
      openAIMessages.add(
        OpenAIChatCompletionChoiceMessageModel(
          role: OpenAIChatMessageRole.user,
          content: [
            OpenAIChatCompletionChoiceMessageContentItemModel.text(
              latestUserText,
            ),
          ],
        ),
      );
    }

    return openAIMessages;
  }

  // å·¥å…·è°ƒç”¨åŠŸèƒ½æš‚æ—¶ç§»é™¤ï¼Œç­‰å¾…OpenAIåŒ…APIç¨³å®š

  /// è½¬æ¢å®ŒæˆåŸå› 
  FinishReason _convertFinishReason(String? reason) {
    switch (reason) {
      case 'stop':
        return FinishReason.stop;
      case 'length':
        return FinishReason.length;
      case 'content_filter':
        return FinishReason.contentFilter;
      case 'tool_calls':
        return FinishReason.toolCalls;
      default:
        return FinishReason.stop;
    }
  }

  // è¾…åŠ©æ–¹æ³•å·²ç§»é™¤ï¼Œå› ä¸ºç°åœ¨ä½¿ç”¨é¢„å®šä¹‰çš„æ¨¡å‹åˆ—è¡¨

  /// å¤„ç†OpenAIé”™è¯¯
  AppException _handleOpenAIError(dynamic error) {
    final errorMessage = error.toString();
    debugPrint('ğŸ” OpenAIé”™è¯¯è¯¦æƒ…: $errorMessage');

    // NoSuchMethodError - é€šå¸¸æ˜¯APIå“åº”æ ¼å¼é—®é¢˜
    if (errorMessage.contains('NoSuchMethodError')) {
      return ApiException('APIå“åº”æ ¼å¼å¼‚å¸¸ï¼Œå¯èƒ½æ˜¯OpenAI APIç‰ˆæœ¬ä¸å…¼å®¹æˆ–å“åº”æ•°æ®ä¸ºç©º');
    }

    // ç½‘ç»œè¿æ¥é”™è¯¯
    if (errorMessage.contains('SocketException')) {
      return NetworkException('ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®æˆ–APIæœåŠ¡åœ°å€æ˜¯å¦æ­£ç¡®');
    }

    // è¶…æ—¶é”™è¯¯
    if (errorMessage.contains('TimeoutException') ||
        errorMessage.contains('è¶…æ—¶')) {
      return NetworkException('è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•');
    }

    // APIè®¤è¯é”™è¯¯
    if (errorMessage.contains('401') || errorMessage.contains('Unauthorized')) {
      return ApiException.invalidApiKey();
    }

    // é€Ÿç‡é™åˆ¶é”™è¯¯
    if (errorMessage.contains('429') || errorMessage.contains('rate limit')) {
      return ApiException.rateLimitExceeded();
    }

    // é…é¢è¶…é™é”™è¯¯
    if (errorMessage.contains('402') || errorMessage.contains('quota')) {
      return ApiException.quotaExceeded();
    }

    // 404é”™è¯¯ - APIç«¯ç‚¹ä¸å­˜åœ¨
    if (errorMessage.contains('404')) {
      return ApiException(
        'APIç«¯ç‚¹ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥baseUrlé…ç½®æ˜¯å¦æ­£ç¡®ã€‚\n'
        'æç¤ºï¼šNewAPIç­‰ç¬¬ä¸‰æ–¹ç½‘å…³çš„baseUrlåº”è¯¥ç±»ä¼¼ï¼šhttp://your-hostï¼ˆä¸è¦åŒ…å«/v1ï¼‰'
      );
    }

    // 500ç³»åˆ—æœåŠ¡å™¨é”™è¯¯
    if (errorMessage.contains('500') ||
        errorMessage.contains('502') ||
        errorMessage.contains('503') ||
        errorMessage.contains('504')) {
      return ApiException('OpenAIæœåŠ¡å™¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•');
    }

    return ApiException('OpenAIè¯·æ±‚å¤±è´¥: $errorMessage');
  }
}
