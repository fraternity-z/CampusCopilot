import 'dart:async';

import 'package:openai_dart/openai_dart.dart';
import 'package:flutter/foundation.dart';

import '../../domain/entities/chat_message.dart';
import '../../domain/providers/llm_provider.dart';
import '../../../../core/exceptions/app_exceptions.dart';

/// OpenAI LLM Providerå®ç°
///
/// ä½¿ç”¨openai_dartåŒ…å®ç°ä¸OpenAI APIçš„äº¤äº’
class OpenAiLlmProvider extends LlmProvider {
  late final OpenAIClient _client;
  
  OpenAiLlmProvider(super.config) {
    _initializeOpenAI();
  }

  @override
  String get providerName => 'OpenAI';

  /// åˆå§‹åŒ–OpenAIé…ç½®
  void _initializeOpenAI() {
    String? baseUrl = config.baseUrl;
    
    if (baseUrl != null) {
      // ä¿®å¤baseUrlé‡å¤/v1çš„é—®é¢˜
      String cleanBaseUrl = baseUrl.trim();
      
      // ç§»é™¤æœ«å°¾çš„æ–œæ 
      if (cleanBaseUrl.endsWith('/')) {
        cleanBaseUrl = cleanBaseUrl.substring(0, cleanBaseUrl.length - 1);
      }
      
      // ç¡®ä¿ä»¥/v1ç»“å°¾ï¼Œå› ä¸ºopenai_dartéœ€è¦å®Œæ•´çš„URL
      if (!cleanBaseUrl.endsWith('/v1')) {
        cleanBaseUrl += '/v1';
      }
      
      baseUrl = cleanBaseUrl;
      debugPrint('ğŸ”§ è®¾ç½®OpenAI baseUrl: $baseUrl (åŸå§‹: ${config.baseUrl})');
    }

    _client = OpenAIClient(
      apiKey: config.apiKey,
      baseUrl: baseUrl,
      organization: config.organizationId,
    );
  }

  // ===== ç¼“å­˜æ¨¡å‹åˆ—è¡¨ï¼Œå‡å°‘é¢‘ç¹çš„ç½‘ç»œè¯·æ±‚ =====
  List<ModelInfo>? _cachedModels;
  DateTime? _cacheTime;
  static const Duration _cacheExpiry = Duration(hours: 1);

  @override
  Future<List<ModelInfo>> listModels() async {
    // å¦‚æœç¼“å­˜ä»ç„¶æœ‰æ•ˆï¼Œç›´æ¥è¿”å›ç¼“å­˜æ•°æ®
    final now = DateTime.now();
    if (_cachedModels != null &&
        _cacheTime != null &&
        now.difference(_cacheTime!) < _cacheExpiry) {
      return _cachedModels!;
    }

    try {
      // è°ƒç”¨ OpenAI åˆ—å‡ºæ¨¡å‹ API
      final response = await _client.listModels();
      final models = response.data;

      // ä»…å–å¯ç”¨çš„æ¨¡å‹ idï¼Œç”Ÿæˆ ModelInfoï¼ˆå…¶å®ƒå­—æ®µç”¨é»˜è®¤ï¼‰
      final List<ModelInfo> result = models.map((m) {
        return ModelInfo(
          id: m.id,
          name: m.id, // é»˜è®¤æ˜¾ç¤ºåç§°ä¸ id ç›¸åŒï¼Œåç»­å¯ç¼–è¾‘
          type: ModelType.chat,
          supportsStreaming: true,
        );
      }).toList();

      // è‹¥ API è¿”å›ç©ºï¼Œé™çº§åˆ°é™æ€åˆ—è¡¨
      if (result.isEmpty) throw Exception('empty');

      // å†™å…¥ç¼“å­˜
      _cachedModels = result;
      _cacheTime = now;
      return result;
    } catch (_) {
      // è¿”å›é™æ€åˆ—è¡¨ä½œä¸ºå…œåº•ï¼Œå¹¶å†™å…¥ç¼“å­˜ï¼Œé¿å…è¿ç»­å¤±è´¥å¯¼è‡´é‡å¤è¯·æ±‚
      const fallback = <ModelInfo>[
        ModelInfo(
          id: 'gpt-3.5-turbo',
          name: 'gpt-3.5-turbo',
          type: ModelType.chat,
          supportsStreaming: true,
        ),
        ModelInfo(
          id: 'gpt-4o',
          name: 'gpt-4o',
          type: ModelType.chat,
          supportsStreaming: true,
          supportsVision: true, // æ”¯æŒè§†è§‰åŠŸèƒ½
          supportsFunctionCalling: true,
        ),
        ModelInfo(
          id: 'text-embedding-3-small',
          name: 'text-embedding-3-small',
          type: ModelType.embedding,
          supportsStreaming: false,
        ),
      ];
      _cachedModels = fallback;
      _cacheTime = now;
      return fallback;
    }
  }

  @override
  Future<ChatResult> generateChat(
    List<ChatMessage> messages, {
    ChatOptions? options,
  }) async {
    try {
      final openAIMessages = _convertToOpenAIMessages(
        messages,
        options?.systemPrompt,
      );
      
      final model = options?.model ?? config.defaultModel ?? 'gpt-3.5-turbo';
      
      final request = CreateChatCompletionRequest(
        model: ChatCompletionModel.modelId(model),
        messages: openAIMessages,
        temperature: options?.temperature ?? 0.7,
        maxTokens: options?.maxTokens ?? 2048,
        frequencyPenalty: options?.frequencyPenalty ?? 0.0,
        presencePenalty: options?.presencePenalty ?? 0.0,
        stop: options?.stopSequences != null 
            ? ChatCompletionStop.listString(options!.stopSequences!) 
            : null,
      );

      final chatCompletion = await _client.createChatCompletion(request: request);

      if (chatCompletion.choices.isEmpty) {
        throw ApiException('OpenAI APIè¿”å›äº†ç©ºçš„é€‰æ‹©åˆ—è¡¨');
      }

      final choice = chatCompletion.choices.first;
      final usage = chatCompletion.usage;

      // ä¿å­˜å®Œæ•´çš„åŸå§‹å†…å®¹
      final originalContent = choice.message.content ?? '';

      debugPrint('ğŸ§  æ¥æ”¶å®Œæ•´å“åº”å†…å®¹: é•¿åº¦=${originalContent.length}');

      return ChatResult(
        content: originalContent, // ä¿å­˜å®Œæ•´å†…å®¹ï¼ŒUIå±‚é¢åˆ†ç¦»æ˜¾ç¤º
        model: model,
        tokenUsage: TokenUsage(
          inputTokens: usage?.promptTokens ?? 0,
          outputTokens: usage?.completionTokens ?? 0,
          totalTokens: usage?.totalTokens ?? 0,
        ),
        finishReason: _convertFinishReason(choice.finishReason?.name),
      );
    } catch (e) {
      throw _handleOpenAIError(e);
    }
  }

  @override
  Stream<StreamedChatResult> generateChatStream(
    List<ChatMessage> messages, {
    ChatOptions? options,
  }) async* {
    try {
      final openAIMessages = _convertToOpenAIMessages(
        messages,
        options?.systemPrompt,
      );
      
      final model = options?.model ?? config.defaultModel ?? 'gpt-3.5-turbo';
      
      final request = CreateChatCompletionRequest(
        model: ChatCompletionModel.modelId(model),
        messages: openAIMessages,
        temperature: options?.temperature ?? 0.7,
        maxTokens: options?.maxTokens ?? 2048,
        frequencyPenalty: options?.frequencyPenalty ?? 0.0,
        presencePenalty: options?.presencePenalty ?? 0.0,
        stop: options?.stopSequences != null 
            ? ChatCompletionStop.listString(options!.stopSequences!) 
            : null,
        stream: true,
      );

      final stream = _client.createChatCompletionStream(request: request);

      String accumulatedContent = ''; // ç´¯ç§¯å®Œæ•´åŸå§‹å†…å®¹

      await for (final chunk in stream) {
        if (chunk.choices?.isEmpty ?? true) continue;

        final choice = chunk.choices!.first;
        final delta = choice.delta;

        // å¤„ç†å†…å®¹å¢é‡
        final deltaContent = delta?.content;
        if (deltaContent != null && deltaContent.isNotEmpty) {
          accumulatedContent += deltaContent;

          yield StreamedChatResult(
            delta: deltaContent,
            content: accumulatedContent, // ä¿å­˜å®Œæ•´å†…å®¹
            isDone: false,
            model: model,
          );
        }

        if (choice.finishReason != null) {
          debugPrint('ğŸ§  æµå¼å“åº”å®Œæˆ: å†…å®¹é•¿åº¦=${accumulatedContent.length}');

          yield StreamedChatResult(
            content: accumulatedContent, // ä¿å­˜å®Œæ•´å†…å®¹ï¼ŒUIå±‚é¢åˆ†ç¦»æ˜¾ç¤º
            isDone: true,
            model: model,
            tokenUsage: TokenUsage(
              inputTokens: 0, // æµå¼å“åº”ä¸­æ— æ³•å‡†ç¡®è·å–
              outputTokens: accumulatedContent.split(' ').length,
              totalTokens: accumulatedContent.split(' ').length,
            ),
            finishReason: _convertFinishReason(choice.finishReason?.name),
          );
        }
      }
    } catch (e) {
      throw _handleOpenAIError(e);
    }
  }

  @override
  Future<EmbeddingResult> generateEmbeddings(List<String> texts) async {
    try {
      final model = config.defaultEmbeddingModel ?? 'text-embedding-3-small';

      debugPrint('ğŸ”— OpenAIåµŒå…¥è¯·æ±‚: æ¨¡å‹=$model, æ–‡æœ¬æ•°é‡=${texts.length}');
      debugPrint('ğŸŒ APIç«¯ç‚¹: ${config.baseUrl ?? 'https://api.openai.com'}');

      final request = CreateEmbeddingRequest(
        model: EmbeddingModel.modelId(model),
        input: EmbeddingInput.listString(texts),
      );

      final embedding = await _client.createEmbedding(request: request)
          .timeout(
            const Duration(minutes: 2), // 2åˆ†é’Ÿè¶…æ—¶
            onTimeout: () {
              throw Exception('OpenAIåµŒå…¥è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIæœåŠ¡çŠ¶æ€');
            },
          );

      // æ£€æŸ¥å“åº”æ•°æ®æ˜¯å¦æœ‰æ•ˆ
      if (embedding.data.isEmpty) {
        throw Exception('OpenAI APIè¿”å›äº†ç©ºçš„åµŒå…¥æ•°æ®');
      }

      debugPrint('âœ… OpenAIåµŒå…¥è¯·æ±‚æˆåŠŸ: ç”Ÿæˆ${embedding.data.length}ä¸ªå‘é‡');

      // å®‰å…¨åœ°å¤„ç†åµŒå…¥æ•°æ®
      final embeddings = <List<double>>[];
      for (final item in embedding.data) {
        // æ ¹æ®æ–‡æ¡£ï¼Œåº”è¯¥ä½¿ç”¨ embeddingVector è€Œä¸æ˜¯ embedding
        final embeddingVector = item.embeddingVector;
        if (embeddingVector.isNotEmpty) {
          embeddings.add(embeddingVector);
        } else {
          debugPrint('âš ï¸ å‘ç°ç©ºçš„åµŒå…¥å‘é‡ï¼Œè·³è¿‡');
        }
      }

      if (embeddings.isEmpty) {
        throw Exception('æ‰€æœ‰åµŒå…¥å‘é‡éƒ½ä¸ºç©º');
      }

      return EmbeddingResult(
        embeddings: embeddings,
        model: model,
        tokenUsage: TokenUsage(
          inputTokens: embedding.usage?.promptTokens ?? 0,
          outputTokens: 0,
          totalTokens: embedding.usage?.totalTokens ?? 0,
        ),
      );
    } catch (e) {
      debugPrint('âŒ OpenAIåµŒå…¥è¯·æ±‚å¤±è´¥: $e');
      debugPrint('ğŸ” OpenAIé”™è¯¯è¯¦æƒ…: $e');

      // æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
      if (e.toString().contains('NoSuchMethodError')) {
        debugPrint('ğŸ’¡ è¿™å¯èƒ½æ˜¯APIå“åº”æ ¼å¼é—®é¢˜ï¼Œè¯·æ£€æŸ¥OpenAI APIç‰ˆæœ¬å…¼å®¹æ€§');
      }

      throw _handleOpenAIError(e);
    }
  }

  @override
  Future<bool> validateConfig() async {
    try {
      await _client.listModels();
      return true;
    } catch (e) {
      return false;
    }
  }

  @override
  int estimateTokens(String text) {
    // ç®€å•çš„tokenä¼°ç®—ï¼šå¤§çº¦4ä¸ªå­—ç¬¦ = 1ä¸ªtoken
    return (text.length / 4).ceil();
  }

  @override
  void dispose() {
    _client.endSession();
  }

  /// è½¬æ¢ä¸ºOpenAIæ¶ˆæ¯æ ¼å¼
  List<ChatCompletionMessage> _convertToOpenAIMessages(
    List<ChatMessage> messages,
    String? systemPrompt,
  ) {
    final openAIMessages = <ChatCompletionMessage>[];

    // æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆæ”¾åœ¨æœ€å‰ï¼‰
    if (systemPrompt != null && systemPrompt.isNotEmpty) {
      openAIMessages.add(
        ChatCompletionMessage.system(
          content: systemPrompt,
        ),
      );
    }

    // è½¬æ¢èŠå¤©æ¶ˆæ¯
    for (final message in messages) {
      if (message.content.isEmpty && message.imageUrls.isEmpty) {
        continue; // è·³è¿‡ç©ºæ¶ˆæ¯
      }

      if (message.imageUrls.isNotEmpty) {
        // å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆæ–‡æœ¬ + å›¾ç‰‡ï¼‰
        final contentParts = <ChatCompletionMessageContentPart>[];
        
        // æ·»åŠ æ–‡æœ¬å†…å®¹
        if (message.content.isNotEmpty) {
          contentParts.add(
            ChatCompletionMessageContentPart.text(text: message.content),
          );
        }
        
        // æ·»åŠ å›¾ç‰‡å†…å®¹
        for (final imageUrl in message.imageUrls) {
          if (imageUrl.startsWith('data:image/') || imageUrl.startsWith('http')) {
            contentParts.add(
              ChatCompletionMessageContentPart.image(
                imageUrl: ChatCompletionMessageImageUrl(
                  url: imageUrl,
                ),
              ),
            );
          } else {
            debugPrint('âš ï¸ ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: $imageUrl');
          }
        }
        
        if (contentParts.isNotEmpty) {
          openAIMessages.add(
            message.isFromUser
                ? ChatCompletionMessage.user(
                    content: ChatCompletionUserMessageContent.parts(contentParts),
                  )
                : ChatCompletionMessage.assistant(
                    content: message.content,
                  ),
          );
        }
      } else {
        // çº¯æ–‡æœ¬æ¶ˆæ¯
        openAIMessages.add(
          message.isFromUser
              ? ChatCompletionMessage.user(
                  content: ChatCompletionUserMessageContent.string(message.content),
                )
              : ChatCompletionMessage.assistant(
                  content: message.content,
                ),
        );
      }
    }

    // å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ¶ˆæ¯ï¼Œæ·»åŠ ä¸€ä¸ªé»˜è®¤æ¶ˆæ¯
    if (openAIMessages.isEmpty ||
        openAIMessages.every((m) => m.role == ChatCompletionMessageRole.system)) {
      openAIMessages.add(
        ChatCompletionMessage.user(
          content: ChatCompletionUserMessageContent.string(
            systemPrompt?.isNotEmpty == true
                ? 'è¯·æ ¹æ®ä¸Šè¿°ç³»ç»ŸæŒ‡ä»¤å›ç­”ã€‚'
                : 'ä½ å¥½ï¼',
          ),
        ),
      );
    }

    return openAIMessages;
  }

  // å·¥å…·è°ƒç”¨åŠŸèƒ½æš‚æ—¶ç§»é™¤ï¼Œç­‰å¾…OpenAIåŒ…APIç¨³å®š

  /// è½¬æ¢å®ŒæˆåŸå› 
  FinishReason _convertFinishReason(String? reason) {
    switch (reason) {
      case 'stop':
        return FinishReason.stop;
      case 'length':
        return FinishReason.length;
      case 'content_filter':
        return FinishReason.contentFilter;
      case 'tool_calls':
        return FinishReason.toolCalls;
      default:
        return FinishReason.stop;
    }
  }

  // è¾…åŠ©æ–¹æ³•å·²ç§»é™¤ï¼Œå› ä¸ºç°åœ¨ä½¿ç”¨é¢„å®šä¹‰çš„æ¨¡å‹åˆ—è¡¨

  /// å¤„ç†OpenAIé”™è¯¯
  AppException _handleOpenAIError(dynamic error) {
    final errorMessage = error.toString();
    debugPrint('ğŸ” OpenAIé”™è¯¯è¯¦æƒ…: $errorMessage');

    // NoSuchMethodError - é€šå¸¸æ˜¯APIå“åº”æ ¼å¼é—®é¢˜
    if (errorMessage.contains('NoSuchMethodError')) {
      return ApiException('APIå“åº”æ ¼å¼å¼‚å¸¸ï¼Œå¯èƒ½æ˜¯OpenAI APIç‰ˆæœ¬ä¸å…¼å®¹æˆ–å“åº”æ•°æ®ä¸ºç©º');
    }

    // ç½‘ç»œè¿æ¥é”™è¯¯
    if (errorMessage.contains('SocketException')) {
      return NetworkException('ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®æˆ–APIæœåŠ¡åœ°å€æ˜¯å¦æ­£ç¡®');
    }

    // è¶…æ—¶é”™è¯¯
    if (errorMessage.contains('TimeoutException') ||
        errorMessage.contains('è¶…æ—¶')) {
      return NetworkException('è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•');
    }

    // APIè®¤è¯é”™è¯¯
    if (errorMessage.contains('401') || errorMessage.contains('Unauthorized')) {
      return ApiException.invalidApiKey();
    }

    // é€Ÿç‡é™åˆ¶é”™è¯¯
    if (errorMessage.contains('429') || errorMessage.contains('rate limit')) {
      return ApiException.rateLimitExceeded();
    }

    // é…é¢è¶…é™é”™è¯¯
    if (errorMessage.contains('402') || errorMessage.contains('quota')) {
      return ApiException.quotaExceeded();
    }

    // 404é”™è¯¯ - APIç«¯ç‚¹ä¸å­˜åœ¨
    if (errorMessage.contains('404')) {
      return ApiException(
        'APIç«¯ç‚¹ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥baseUrlé…ç½®æ˜¯å¦æ­£ç¡®ã€‚\n'
        'æç¤ºï¼šNewAPIç­‰ç¬¬ä¸‰æ–¹ç½‘å…³çš„baseUrlåº”è¯¥ç±»ä¼¼ï¼šhttp://your-hostï¼ˆä¸è¦åŒ…å«/v1ï¼‰'
      );
    }

    // 500ç³»åˆ—æœåŠ¡å™¨é”™è¯¯
    if (errorMessage.contains('500') ||
        errorMessage.contains('502') ||
        errorMessage.contains('503') ||
        errorMessage.contains('504')) {
      return ApiException('OpenAIæœåŠ¡å™¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•');
    }

    return ApiException('OpenAIè¯·æ±‚å¤±è´¥: $errorMessage');
  }
}
