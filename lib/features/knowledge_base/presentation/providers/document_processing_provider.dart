import 'package:flutter/foundation.dart';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:drift/drift.dart';
import 'dart:convert';

import '../../domain/services/document_processing_service.dart';
import '../../domain/services/embedding_service.dart';
import '../../domain/services/vector_database_interface.dart';
import '../../data/providers/vector_database_provider.dart';
import '../../../../core/di/database_providers.dart';
import '../../../../data/local/app_database.dart';
import 'knowledge_base_config_provider.dart';

/// æ–‡æ¡£å¤„ç†çŠ¶æ€
class DocumentProcessingState {
  final Map<String, double> processingProgress; // æ–‡æ¡£ID -> è¿›åº¦
  final Map<String, String?> processingErrors; // æ–‡æ¡£ID -> é”™è¯¯ä¿¡æ¯
  final bool isProcessing;

  const DocumentProcessingState({
    this.processingProgress = const {},
    this.processingErrors = const {},
    this.isProcessing = false,
  });

  DocumentProcessingState copyWith({
    Map<String, double>? processingProgress,
    Map<String, String?>? processingErrors,
    bool? isProcessing,
  }) {
    return DocumentProcessingState(
      processingProgress: processingProgress ?? this.processingProgress,
      processingErrors: processingErrors ?? this.processingErrors,
      isProcessing: isProcessing ?? this.isProcessing,
    );
  }
}

/// æ–‡æ¡£å¤„ç†ç®¡ç†å™¨
class DocumentProcessingNotifier
    extends StateNotifier<DocumentProcessingState> {
  final AppDatabase _database;
  final DocumentProcessingService _processingService;
  final EmbeddingService _embeddingService;
  final Ref _ref;

  DocumentProcessingNotifier(
    this._database,
    this._processingService,
    this._embeddingService,
    this._ref,
  ) : super(const DocumentProcessingState());

  /// å¤„ç†å•ä¸ªæ–‡æ¡£
  Future<void> processDocument({
    required String documentId,
    required String filePath,
    required String fileType,
    required String knowledgeBaseId,
    int chunkSize = 1000,
    int chunkOverlap = 200,
  }) async {
    try {
      debugPrint('ğŸ”„ å¼€å§‹å¤„ç†æ–‡æ¡£: $documentId');

      // æ›´æ–°å¤„ç†çŠ¶æ€
      _updateProgress(documentId, 0.0);
      await _updateDocumentStatus(documentId, 'processing');
      debugPrint('ğŸ“Š æ–‡æ¡£çŠ¶æ€å·²æ›´æ–°ä¸ºprocessing');

      // å¤„ç†æ–‡æ¡£ï¼ˆæ·»åŠ è¶…æ—¶æœºåˆ¶ï¼‰
      debugPrint('ğŸ“„ å¼€å§‹æå–æ–‡æ¡£å†…å®¹...');
      final result = await _processingService
          .processDocument(
            documentId: documentId,
            filePath: filePath,
            fileType: fileType,
            chunkSize: chunkSize,
            chunkOverlap: chunkOverlap,
          )
          .timeout(
            const Duration(minutes: 10), // 10åˆ†é’Ÿè¶…æ—¶
            onTimeout: () {
              debugPrint('â° æ–‡æ¡£å¤„ç†è¶…æ—¶: $documentId');
              return DocumentProcessingResult(
                chunks: [],
                error: 'æ–‡æ¡£å¤„ç†è¶…æ—¶ï¼ˆè¶…è¿‡10åˆ†é’Ÿï¼‰',
              );
            },
          );

      if (result.isSuccess) {
        debugPrint('âœ… æ–‡æ¡£å¤„ç†æˆåŠŸï¼Œç”Ÿæˆäº†${result.chunks.length}ä¸ªæ–‡æœ¬å—');

        // ä¿å­˜æ–‡æœ¬å—åˆ°æ•°æ®åº“
        _updateProgress(documentId, 0.4);
        debugPrint('ğŸ’¾ ä¿å­˜æ–‡æœ¬å—åˆ°æ•°æ®åº“...');
        await _saveChunksToDatabase(documentId, knowledgeBaseId, result.chunks);

        // ç”ŸæˆåµŒå…¥å‘é‡
        _updateProgress(documentId, 0.6);
        debugPrint('ğŸ§  ç”ŸæˆåµŒå…¥å‘é‡...');
        await _generateEmbeddingsForChunks(documentId, result.chunks);

        // æ›´æ–°æ–‡æ¡£çŠ¶æ€
        _updateProgress(documentId, 1.0);
        debugPrint('ğŸ‰ æ›´æ–°æ–‡æ¡£çŠ¶æ€ä¸ºcompleted');
        await _updateDocumentStatus(documentId, 'completed');
        await _updateDocumentMetadata(documentId, result.metadata);

        // æ¸…é™¤è¿›åº¦ä¿¡æ¯
        _clearProgress(documentId);
        debugPrint('âœ… æ–‡æ¡£å¤„ç†å®Œæˆ: $documentId');
      } else {
        // å¤„ç†å¤±è´¥
        debugPrint('âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: ${result.error}');
        await _updateDocumentStatus(documentId, 'failed', result.error);
        _updateError(documentId, result.error);
      }
    } catch (e, stackTrace) {
      debugPrint('ğŸ’¥ æ–‡æ¡£å¤„ç†å¼‚å¸¸: $e');
      debugPrint('å †æ ˆè·Ÿè¸ª: $stackTrace');
      await _updateDocumentStatus(documentId, 'failed', e.toString());
      _updateError(documentId, e.toString());
    }
  }

  /// æ‰¹é‡å¤„ç†æ–‡æ¡£
  Future<void> processAllPendingDocuments({
    int chunkSize = 1000,
    int chunkOverlap = 200,
  }) async {
    try {
      state = state.copyWith(isProcessing: true);

      // è·å–å¾…å¤„ç†çš„æ–‡æ¡£
      final pendingDocs = await _database.getDocumentsByStatus('pending');

      for (final doc in pendingDocs) {
        await processDocument(
          documentId: doc.id,
          filePath: doc.filePath,
          fileType: doc.type,
          knowledgeBaseId: doc.knowledgeBaseId,
          chunkSize: chunkSize,
          chunkOverlap: chunkOverlap,
        );
      }
    } finally {
      state = state.copyWith(isProcessing: false);
    }
  }

  /// é‡æ–°å¤„ç†æ–‡æ¡£
  Future<void> reprocessDocument({
    required String documentId,
    int chunkSize = 1000,
    int chunkOverlap = 200,
  }) async {
    try {
      // åˆ é™¤ç°æœ‰çš„æ–‡æœ¬å—
      await _database.deleteChunksByDocument(documentId);

      // è·å–æ–‡æ¡£ä¿¡æ¯
      final doc = await _database.getAllKnowledgeDocuments().then(
        (docs) => docs.where((d) => d.id == documentId).firstOrNull,
      );

      if (doc != null) {
        await processDocument(
          documentId: documentId,
          filePath: doc.filePath,
          fileType: doc.type,
          knowledgeBaseId: doc.knowledgeBaseId,
          chunkSize: chunkSize,
          chunkOverlap: chunkOverlap,
        );
      }
    } catch (e) {
      _updateError(documentId, e.toString());
    }
  }

  /// ä¿å­˜æ–‡æœ¬å—åˆ°æ•°æ®åº“
  Future<void> _saveChunksToDatabase(
    String documentId,
    String knowledgeBaseId,
    List<DocumentChunk> chunks,
  ) async {
    final companions = chunks.map((chunk) {
      return KnowledgeChunksTableCompanion.insert(
        id: chunk.id,
        knowledgeBaseId: knowledgeBaseId,
        documentId: documentId,
        content: chunk.content,
        chunkIndex: chunk.index,
        characterCount: chunk.characterCount,
        tokenCount: chunk.tokenCount,
        createdAt: DateTime.now(),
      );
    }).toList();

    await _database.insertKnowledgeChunks(companions);

    // æ›´æ–°æ–‡æ¡£çš„å—æ•°é‡
    await (_database.update(
      _database.knowledgeDocumentsTable,
    )..where((t) => t.id.equals(documentId))).write(
      KnowledgeDocumentsTableCompanion(
        chunks: Value(chunks.length),
        processedAt: Value(DateTime.now()),
      ),
    );
  }

  /// æ›´æ–°æ–‡æ¡£çŠ¶æ€
  Future<void> _updateDocumentStatus(
    String documentId,
    String status, [
    String? errorMessage,
  ]) async {
    // ä½¿ç”¨updateè¯­å¥åªæ›´æ–°ç‰¹å®šå­—æ®µï¼Œé¿å…æ•°æ®éªŒè¯é”™è¯¯
    await (_database.update(
      _database.knowledgeDocumentsTable,
    )..where((t) => t.id.equals(documentId))).write(
      KnowledgeDocumentsTableCompanion(
        status: Value(status),
        errorMessage: Value(errorMessage),
        processedAt: Value(DateTime.now()),
      ),
    );
  }

  /// æ›´æ–°æ–‡æ¡£å…ƒæ•°æ®
  Future<void> _updateDocumentMetadata(
    String documentId,
    Map<String, dynamic> metadata,
  ) async {
    // ä½¿ç”¨updateè¯­å¥åªæ›´æ–°å…ƒæ•°æ®å­—æ®µ
    await (_database.update(
      _database.knowledgeDocumentsTable,
    )..where((t) => t.id.equals(documentId))).write(
      KnowledgeDocumentsTableCompanion(
        metadata: Value(metadata.isNotEmpty ? jsonEncode(metadata) : null),
      ),
    );
  }

  /// æ›´æ–°å¤„ç†è¿›åº¦
  void _updateProgress(String documentId, double progress) {
    final newProgress = Map<String, double>.from(state.processingProgress);
    newProgress[documentId] = progress;
    state = state.copyWith(processingProgress: newProgress);
  }

  /// æ¸…é™¤è¿›åº¦ä¿¡æ¯
  void _clearProgress(String documentId) {
    final newProgress = Map<String, double>.from(state.processingProgress);
    final newErrors = Map<String, String?>.from(state.processingErrors);
    newProgress.remove(documentId);
    newErrors.remove(documentId);
    state = state.copyWith(
      processingProgress: newProgress,
      processingErrors: newErrors,
    );
  }

  /// æ›´æ–°é”™è¯¯ä¿¡æ¯
  void _updateError(String documentId, String? error) {
    final newErrors = Map<String, String?>.from(state.processingErrors);
    newErrors[documentId] = error;
    state = state.copyWith(processingErrors: newErrors);
  }

  /// è·å–æ–‡æ¡£å¤„ç†è¿›åº¦
  double? getDocumentProgress(String documentId) {
    return state.processingProgress[documentId];
  }

  /// è·å–æ–‡æ¡£å¤„ç†é”™è¯¯
  String? getDocumentError(String documentId) {
    return state.processingErrors[documentId];
  }

  /// ä¸ºæ–‡æœ¬å—ç”ŸæˆåµŒå…¥å‘é‡ï¼ˆæ‰¹å¤„ç†ç‰ˆæœ¬ï¼‰
  Future<void> _generateEmbeddingsForChunks(
    String documentId,
    List<DocumentChunk> chunks,
  ) async {
    try {
      debugPrint('ğŸ§  å¼€å§‹ç”ŸæˆåµŒå…¥å‘é‡ï¼Œæ€»å…± ${chunks.length} ä¸ªæ–‡æœ¬å—');

      // è·å–çŸ¥è¯†åº“é…ç½®
      final config = _ref.read(knowledgeBaseConfigProvider).currentConfig;
      if (config == null) {
        throw Exception('æœªæ‰¾åˆ°çŸ¥è¯†åº“é…ç½®');
      }

      // åˆ†æ‰¹å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§å¤„ç†å¤ªå¤šæ–‡æœ¬å—å¯¼è‡´è¶…æ—¶
      // æ ¹æ®æ–‡æ¡£è§„æ¨¡åŠ¨æ€è°ƒæ•´æ‰¹å¤§å°ï¼Œé»˜è®¤ 50ï¼Œå¯é€šè¿‡é…ç½®è¦†ç›–
      const batchSize = 50; // æ¯æ‰¹å¤„ç†50ä¸ªæ–‡æœ¬å—ï¼Œæé«˜ååé‡
      int processedCount = 0;

      for (int i = 0; i < chunks.length; i += batchSize) {
        final endIndex = (i + batchSize < chunks.length)
            ? i + batchSize
            : chunks.length;
        final batchChunks = chunks.sublist(i, endIndex);
        final batchTexts = batchChunks.map((chunk) => chunk.content).toList();

        debugPrint(
          'ğŸ”„ å¤„ç†ç¬¬ ${(i / batchSize).floor() + 1} æ‰¹ï¼ŒåŒ…å« ${batchChunks.length} ä¸ªæ–‡æœ¬å—',
        );

        try {
          // ç”Ÿæˆå½“å‰æ‰¹æ¬¡çš„åµŒå…¥å‘é‡
          final result = await _embeddingService.generateEmbeddingsForChunks(
            chunks: batchTexts,
            config: config,
          );

          if (result.isSuccess) {
            // å‡†å¤‡å‘é‡æ–‡æ¡£åˆ—è¡¨
            final vectorDocuments = <VectorDocument>[];

            // ä¿å­˜åµŒå…¥å‘é‡åˆ°å…³ç³»å‹æ•°æ®åº“å’Œå‘é‡æ•°æ®åº“
            for (int j = 0; j < batchChunks.length; j++) {
              if (j < result.embeddings.length) {
                final chunk = batchChunks[j];
                final embedding = result.embeddings[j];
                final embeddingJson = jsonEncode(embedding);

                // ä¿å­˜åˆ°å…³ç³»å‹æ•°æ®åº“
                await _database.updateChunkEmbedding(chunk.id, embeddingJson);

                // å‡†å¤‡å‘é‡æ–‡æ¡£
                vectorDocuments.add(
                  VectorDocument(
                    id: chunk.id,
                    vector: embedding,
                    metadata: {
                      'documentId': documentId,
                      'chunkIndex': chunk.index,
                      'content': chunk.content,
                      'characterCount': chunk.characterCount,
                      'tokenCount': chunk.tokenCount,
                      'createdAt': DateTime.now().toIso8601String(),
                    },
                  ),
                );
              }
            }

            // æ‰¹é‡ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
            if (vectorDocuments.isNotEmpty) {
              await _saveVectorsToVectorDatabase(vectorDocuments, documentId);
            }

            processedCount += batchChunks.length;
            debugPrint('âœ… å·²å®Œæˆ $processedCount/${chunks.length} ä¸ªæ–‡æœ¬å—çš„åµŒå…¥å‘é‡ç”Ÿæˆ');
          } else {
            debugPrint(
              'âŒ ç¬¬ ${(i / batchSize).floor() + 1} æ‰¹åµŒå…¥å‘é‡ç”Ÿæˆå¤±è´¥: ${result.error}',
            );
            // ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
          }
        } catch (batchError) {
          debugPrint('âŒ ç¬¬ ${(i / batchSize).floor() + 1} æ‰¹å¤„ç†å¼‚å¸¸: $batchError');
          // ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹
        }

        // å¦‚æœ‰å¿…è¦å¯æ ¹æ®å…·ä½“ API é™æµç­–ç•¥åœ¨æ­¤å¤„æ·»åŠ å»¶è¿Ÿï¼Œé»˜è®¤ä¸ç­‰å¾…
      }

      debugPrint('ğŸ‰ åµŒå…¥å‘é‡ç”Ÿæˆå®Œæˆï¼ŒæˆåŠŸå¤„ç† $processedCount/${chunks.length} ä¸ªæ–‡æœ¬å—');
    } catch (e) {
      // åµŒå…¥ç”Ÿæˆå¤±è´¥ä¸åº”è¯¥å½±å“æ•´ä¸ªæ–‡æ¡£å¤„ç†æµç¨‹
      // åªè®°å½•é”™è¯¯ï¼Œæ–‡æ¡£ä»ç„¶å¯ä»¥è¢«æ ‡è®°ä¸ºå·²å®Œæˆ
      debugPrint('âŒ ä¸ºæ–‡æ¡£ $documentId ç”ŸæˆåµŒå…¥å‘é‡å¤±è´¥: $e');
    }
  }

  /// ä¿å­˜å‘é‡åˆ°å‘é‡æ•°æ®åº“
  Future<void> _saveVectorsToVectorDatabase(
    List<VectorDocument> vectorDocuments,
    String documentId,
  ) async {
    try {
      // ä»æ–‡æœ¬å—ä¸­è·å–çŸ¥è¯†åº“ID
      final chunks = await _database.getChunksByDocument(documentId);
      String knowledgeBaseId = 'default_kb';

      if (chunks.isNotEmpty) {
        knowledgeBaseId = chunks.first.knowledgeBaseId;
      }

      debugPrint(
        'ğŸ’¾ ä¿å­˜ ${vectorDocuments.length} ä¸ªå‘é‡åˆ°å‘é‡æ•°æ®åº“ï¼ŒçŸ¥è¯†åº“: $knowledgeBaseId',
      );

      // è·å–å‘é‡æ•°æ®åº“
      final vectorDatabase = await _ref.read(vectorDatabaseProvider.future);

      // ç¡®ä¿ç›®æ ‡é›†åˆå­˜åœ¨ï¼Œè‹¥ä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»º
      debugPrint('ğŸ” æ£€æŸ¥å‘é‡é›†åˆæ˜¯å¦å­˜åœ¨: $knowledgeBaseId');
      final collectionExists = await vectorDatabase.collectionExists(
        knowledgeBaseId,
      );
      debugPrint('ğŸ“Š é›†åˆå­˜åœ¨çŠ¶æ€: $collectionExists');

      if (!collectionExists) {
        debugPrint('ğŸ”§ è‡ªåŠ¨åˆ›å»ºå‘é‡é›†åˆ: $knowledgeBaseId');
        // ä½¿ç”¨é¦–ä¸ªå‘é‡çš„ç»´åº¦ä½œä¸ºé›†åˆç»´åº¦
        final vectorDim = vectorDocuments.first.vector.length;
        debugPrint('ğŸ“ å‘é‡ç»´åº¦: $vectorDim');

        final createResult = await vectorDatabase.createCollection(
          collectionName: knowledgeBaseId,
          vectorDimension: vectorDim,
          description: 'çŸ¥è¯†åº“ $knowledgeBaseId çš„å‘é‡é›†åˆ',
          metadata: {
            'knowledgeBaseId': knowledgeBaseId,
            'createdAt': DateTime.now().toIso8601String(),
            'autoCreated': 'true',
          },
        );

        if (createResult.success) {
          debugPrint('âœ… å‘é‡é›†åˆåˆ›å»ºæˆåŠŸ: $knowledgeBaseId');
        } else {
          debugPrint('âŒ å‘é‡é›†åˆåˆ›å»ºå¤±è´¥: $knowledgeBaseId - ${createResult.error}');
          throw Exception('åˆ›å»ºå‘é‡é›†åˆå¤±è´¥: ${createResult.error}');
        }
      } else {
        debugPrint('âœ… å‘é‡é›†åˆå·²å­˜åœ¨: $knowledgeBaseId');
      }

      // æ‰¹é‡æ’å…¥å‘é‡
      debugPrint('ğŸ“ æ’å…¥ ${vectorDocuments.length} ä¸ªå‘é‡åˆ°é›†åˆ: $knowledgeBaseId');
      final result = await vectorDatabase.insertVectors(
        collectionName: knowledgeBaseId,
        documents: vectorDocuments,
      );

      if (result.success) {
        debugPrint('âœ… å‘é‡ä¿å­˜æˆåŠŸ: ${vectorDocuments.length} ä¸ªå‘é‡');
      } else {
        debugPrint('âŒ å‘é‡ä¿å­˜å¤±è´¥: ${result.error}');
        // å¦‚æœæ’å…¥å¤±è´¥ï¼Œå†æ¬¡æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
        final stillExists = await vectorDatabase.collectionExists(
          knowledgeBaseId,
        );
        debugPrint('ğŸ” æ’å…¥å¤±è´¥åé›†åˆå­˜åœ¨çŠ¶æ€: $stillExists');
        throw Exception('æ’å…¥å‘é‡å¤±è´¥: ${result.error}');
      }
    } catch (e) {
      debugPrint('âŒ ä¿å­˜å‘é‡åˆ°å‘é‡æ•°æ®åº“å¼‚å¸¸: $e');
    }
  }
}

/// æ–‡æ¡£å¤„ç†æœåŠ¡Provider
final documentProcessingServiceProvider = Provider<DocumentProcessingService>((
  ref,
) {
  return DocumentProcessingService();
});

/// åµŒå…¥æœåŠ¡Provider
final embeddingServiceProvider = Provider<EmbeddingService>((ref) {
  final database = ref.read(appDatabaseProvider);
  return EmbeddingService(database);
});

/// æ–‡æ¡£å¤„ç†Provider
final documentProcessingProvider =
    StateNotifierProvider<DocumentProcessingNotifier, DocumentProcessingState>((
      ref,
    ) {
      final database = ref.read(appDatabaseProvider);
      final processingService = ref.read(documentProcessingServiceProvider);
      final embeddingService = ref.read(embeddingServiceProvider);
      return DocumentProcessingNotifier(
        database,
        processingService,
        embeddingService,
        ref,
      );
    });

/// æ–‡æ¡£å¤„ç†è¿›åº¦Provider
final documentProgressProvider = Provider.family<double?, String>((
  ref,
  documentId,
) {
  return ref.watch(documentProcessingProvider).processingProgress[documentId];
});

/// æ–‡æ¡£å¤„ç†é”™è¯¯Provider
final documentErrorProvider = Provider.family<String?, String>((
  ref,
  documentId,
) {
  return ref.watch(documentProcessingProvider).processingErrors[documentId];
});
