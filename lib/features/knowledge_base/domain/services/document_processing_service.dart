import 'dart:convert';
import 'dart:io';

import 'package:flutter/foundation.dart';
import 'package:archive/archive.dart';
import 'package:xml/xml.dart';

/// æ–‡æ¡£å—å®ä½“
class DocumentChunk {
  final String id;
  final String content;
  final int index;
  final int characterCount;
  final int tokenCount;
  final Map<String, dynamic> metadata;

  const DocumentChunk({
    required this.id,
    required this.content,
    required this.index,
    required this.characterCount,
    required this.tokenCount,
    this.metadata = const {},
  });
}

/// æ–‡æ¡£å¤„ç†ç»“æœ
class DocumentProcessingResult {
  final List<DocumentChunk> chunks;
  final Map<String, dynamic> metadata;
  final String? error;

  const DocumentProcessingResult({
    required this.chunks,
    this.metadata = const {},
    this.error,
  });

  bool get isSuccess => error == null;
}

/// æ–‡æœ¬æå–ç»“æœ
class TextExtractionResult {
  final String text;
  final String? error;

  const TextExtractionResult({required this.text, this.error});
}

/// æ–‡æ¡£å¤„ç†æœåŠ¡
class DocumentProcessingService {
  /// å¤„ç†æ–‡æ¡£å¹¶åˆ†å—
  Future<DocumentProcessingResult> processDocument({
    required String documentId,
    required String filePath,
    required String fileType,
    int chunkSize = 1000,
    int chunkOverlap = 200,
  }) async {
    try {
      // 1. æå–æ–‡æœ¬å†…å®¹
      final extractResult = await _extractText(filePath, fileType);
      if (extractResult.error != null) {
        return DocumentProcessingResult(chunks: [], error: extractResult.error);
      }

      // 2. åˆ†å—å¤„ç†
      final chunks = await _splitIntoChunks(
        documentId: documentId,
        text: extractResult.text,
        chunkSize: chunkSize,
        chunkOverlap: chunkOverlap,
      );

      return DocumentProcessingResult(
        chunks: chunks,
        metadata: {
          'originalLength': extractResult.text.length,
          'chunkCount': chunks.length,
          'chunkSize': chunkSize,
          'chunkOverlap': chunkOverlap,
          'fileType': fileType,
          'processedAt': DateTime.now().toIso8601String(),
        },
      );
    } catch (e) {
      debugPrint('æ–‡æ¡£å¤„ç†å¤±è´¥: $e');
      return DocumentProcessingResult(chunks: [], error: e.toString());
    }
  }

  /// ä»æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹ï¼ˆå…¬å…±æ–¹æ³•ï¼‰
  Future<TextExtractionResult> extractTextFromFile(
    String filePath,
    String fileType,
  ) async {
    return _extractText(filePath, fileType);
  }

  /// æå–æ–‡æœ¬å†…å®¹
  Future<TextExtractionResult> _extractText(
    String filePath,
    String fileType,
  ) async {
    try {
      final file = File(filePath);
      if (!await file.exists()) {
        return const TextExtractionResult(text: '', error: 'æ–‡ä»¶ä¸å­˜åœ¨');
      }

      switch (fileType.toLowerCase()) {
        case 'txt':
        case 'md':
        case 'markdown':
          return TextExtractionResult(
            text: await file.readAsString(encoding: utf8),
          );

        case 'pdf':
          return await _extractPdfText(filePath);

        case 'docx':
          return await _extractDocxText(filePath);

        case 'pptx':
          return await _extractPptxText(filePath);

        case 'xlsx':
          return await _extractXlsxText(filePath);

        case 'rtf':
          return await _extractRtfText(filePath);

        case 'csv':
          return await _extractCsvText(filePath);

        case 'json':
          return await _extractJsonText(filePath);

        case 'xml':
          return await _extractXmlText(filePath);

        case 'html':
        case 'htm':
          return await _extractHtmlText(filePath);

        default:
          // å°è¯•ä½œä¸ºçº¯æ–‡æœ¬è¯»å–
          try {
            final text = await file.readAsString(encoding: utf8);
            return TextExtractionResult(text: text);
          } catch (e) {
            return TextExtractionResult(text: '', error: 'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: $fileType');
          }
      }
    } catch (e) {
      return TextExtractionResult(text: '', error: 'æ–‡æœ¬æå–å¤±è´¥: $e');
    }
  }

  /// å°†æ–‡æœ¬åˆ†å‰²æˆå—ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼Œé¿å…UIå¡ä½ï¼‰
  Future<List<DocumentChunk>> _splitIntoChunks({
    required String documentId,
    required String text,
    required int chunkSize,
    required int chunkOverlap,
  }) async {
    if (text.isEmpty) return [];

    // éªŒè¯å‚æ•°åˆç†æ€§
    if (chunkOverlap >= chunkSize) {
      debugPrint(
        'âš ï¸ è­¦å‘Šï¼šé‡å å¤§å°($chunkOverlap)ä¸èƒ½å¤§äºç­‰äºå—å¤§å°($chunkSize)ï¼Œè‡ªåŠ¨è°ƒæ•´ä¸º${(chunkSize * 0.2).round()}',
      );
      chunkOverlap = (chunkSize * 0.2).round(); // è®¾ç½®ä¸ºå—å¤§å°çš„20%
    }

    debugPrint(
      'ğŸ“ å¼€å§‹åˆ†å—å¤„ç†ï¼Œæ–‡æœ¬é•¿åº¦: ${text.length}, å—å¤§å°: $chunkSize, é‡å : $chunkOverlap',
    );
    final chunks = <DocumentChunk>[];
    int start = 0;
    int chunkIndex = 0;
    int processedChars = 0;
    int lastStart = -1; // ç”¨äºæ£€æµ‹æ— é™å¾ªç¯

    while (start < text.length) {
      // æ£€æµ‹æ— é™å¾ªç¯
      if (start == lastStart) {
        debugPrint('âŒ æ£€æµ‹åˆ°æ— é™å¾ªç¯ï¼Œå¼ºåˆ¶é€€å‡ºã€‚start=$start, lastStart=$lastStart');
        break;
      }
      lastStart = start;

      // æ¯å¤„ç†ä¸€å®šæ•°é‡çš„å­—ç¬¦åï¼Œè®©å‡ºæ§åˆ¶æƒç»™UIçº¿ç¨‹
      if (processedChars > 10000) {
        await Future.delayed(const Duration(milliseconds: 1));
        processedChars = 0;
      }

      // è®¡ç®—å½“å‰å—çš„ç»“æŸä½ç½®
      int end = start + chunkSize;
      if (end > text.length) {
        end = text.length;
      }

      // å°è¯•åœ¨å¥å­è¾¹ç•Œåˆ†å‰²ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
      if (end < text.length) {
        final sentenceEnd = _findSentenceEndSimple(text, end);
        if (sentenceEnd > start && sentenceEnd - start <= chunkSize + 100) {
          end = sentenceEnd;
        }
      }

      // æå–å—å†…å®¹
      final chunkContent = text.substring(start, end).trim();
      if (chunkContent.isNotEmpty) {
        final chunkId = '${documentId}_chunk_$chunkIndex';
        final chunk = DocumentChunk(
          id: chunkId,
          content: chunkContent,
          index: chunkIndex,
          characterCount: chunkContent.length,
          tokenCount: _estimateTokenCount(chunkContent),
          metadata: {'startPosition': start, 'endPosition': end},
        );
        chunks.add(chunk);
        chunkIndex++;

        // æ¯10ä¸ªå—è¾“å‡ºä¸€æ¬¡è¿›åº¦
        if (chunkIndex % 10 == 0) {
          debugPrint('ğŸ“Š å·²å¤„ç† $chunkIndex ä¸ªæ–‡æœ¬å—');
        }
      }

      // è®¡ç®—ä¸‹ä¸€ä¸ªå—çš„å¼€å§‹ä½ç½®ï¼ˆè€ƒè™‘é‡å ï¼‰
      int nextStart = end - chunkOverlap;

      // ç¡®ä¿ä¸‹ä¸€ä¸ªå¼€å§‹ä½ç½®æœ‰æ•ˆ
      if (nextStart <= start) {
        // å¦‚æœè®¡ç®—å‡ºçš„ä¸‹ä¸€ä¸ªä½ç½®æ²¡æœ‰å‰è¿›ï¼Œå¼ºåˆ¶å‰è¿›è‡³å°‘1ä¸ªå­—ç¬¦
        nextStart = start + 1;
        debugPrint(
          'âš ï¸ è°ƒæ•´ä¸‹ä¸€ä¸ªå¼€å§‹ä½ç½®: $start -> $nextStart (åŸè®¡ç®—å€¼: ${end - chunkOverlap})',
        );
      }

      start = nextStart;

      // è¾¹ç•Œæ£€æŸ¥
      if (start >= text.length) {
        break;
      }

      processedChars += (end - (start - 1));

      // å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœå—æ•°é‡è¿‡å¤šï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜
      if (chunkIndex > text.length / 10) {
        debugPrint('âŒ å—æ•°é‡å¼‚å¸¸è¿‡å¤š($chunkIndex)ï¼Œå¯èƒ½å­˜åœ¨æ— é™å¾ªç¯ï¼Œå¼ºåˆ¶é€€å‡º');
        break;
      }
    }

    debugPrint('âœ… åˆ†å—å®Œæˆï¼Œæ€»å…±ç”Ÿæˆ ${chunks.length} ä¸ªæ–‡æœ¬å—');
    return chunks;
  }

  /// æŸ¥æ‰¾å¥å­ç»“æŸä½ç½®ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œæ›´é«˜æ•ˆï¼‰
  int _findSentenceEndSimple(String text, int position) {
    // ç®€åŒ–ç‰ˆæœ¬ï¼šåªæŸ¥æ‰¾æœ€å¸¸è§çš„å¥å­ç»“æŸç¬¦ï¼ŒèŒƒå›´æ›´å°
    const sentenceEnders = ['.', 'ã€‚', '\n'];

    // å‘å‰æŸ¥æ‰¾æœ€è¿‘çš„å¥å­ç»“æŸç¬¦ï¼ˆèŒƒå›´ç¼©å°åˆ°50ä¸ªå­—ç¬¦ï¼‰
    for (int i = position; i < text.length && i < position + 50; i++) {
      if (sentenceEnders.contains(text[i])) {
        return i + 1;
      }
    }

    // å‘åæŸ¥æ‰¾ï¼ˆèŒƒå›´ç¼©å°åˆ°50ä¸ªå­—ç¬¦ï¼‰
    for (int i = position - 1; i >= 0 && i > position - 50; i--) {
      if (sentenceEnders.contains(text[i])) {
        return i + 1;
      }
    }

    return position;
  }

  /// ä¼°ç®—tokenæ•°é‡ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
  int _estimateTokenCount(String text) {
    if (text.isEmpty) return 0;

    // ç®€åŒ–çš„tokenä¼°ç®—ï¼šé¿å…å¤æ‚çš„æ­£åˆ™è¡¨è¾¾å¼
    // å¤§è‡´æŒ‰ç…§å­—ç¬¦æ•°é™¤ä»¥4æ¥ä¼°ç®—ï¼ˆè¿™æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„ç»éªŒå€¼ï¼‰
    // å¯¹äºä¸­è‹±æ–‡æ··åˆæ–‡æœ¬ï¼Œè¿™ä¸ªä¼°ç®—ç›¸å¯¹å‡†ç¡®ä¸”é«˜æ•ˆ
    return (text.length / 4).ceil();
  }

  /// æå–PDFæ–‡æœ¬å†…å®¹
  Future<TextExtractionResult> _extractPdfText(String filePath) async {
    try {
      debugPrint('ğŸ“„ å¼€å§‹å¤„ç†PDFæ–‡ä»¶: $filePath');
      final file = File(filePath);

      if (!await file.exists()) {
        return const TextExtractionResult(text: '', error: 'PDFæ–‡ä»¶ä¸å­˜åœ¨');
      }

      final bytes = await file.readAsBytes();
      debugPrint('ğŸ“Š PDFæ–‡ä»¶å¤§å°: ${bytes.length} bytes');

      // æš‚æ—¶è¿”å›æç¤ºä¿¡æ¯ï¼ŒPDFæ–‡æœ¬æå–éœ€è¦ä¸“é—¨çš„åº“
      // å»ºè®®ç”¨æˆ·å°†PDFè½¬æ¢ä¸ºæ–‡æœ¬æ–‡ä»¶æˆ–ä½¿ç”¨æ”¯æŒPDFè§£æçš„ä¸“é—¨åº“
      return TextExtractionResult(
        text: '',
        error:
            'PDFæ–‡æœ¬æå–åŠŸèƒ½æš‚æœªå®Œå…¨å®ç°ã€‚å»ºè®®ï¼š\n'
            '1. å°†PDFå†…å®¹å¤åˆ¶ç²˜è´´ä¸ºæ–‡æœ¬æ–‡ä»¶ä¸Šä¼ \n'
            '2. ä½¿ç”¨æ”¯æŒæ–‡æœ¬é€‰æ‹©çš„PDFæŸ¥çœ‹å™¨å¤åˆ¶å†…å®¹\n'
            '3. å°†PDFè½¬æ¢ä¸ºWordæ–‡æ¡£åä¸Šä¼ \n'
            'æ³¨æ„ï¼šæ‰«æç‰ˆPDFæ— æ³•ç›´æ¥æå–æ–‡æœ¬ï¼Œéœ€è¦OCRå¤„ç†ã€‚',
      );
    } catch (e, stackTrace) {
      debugPrint('ğŸ’¥ PDFæ–‡ä»¶å¤„ç†å¼‚å¸¸: $e');
      debugPrint('å †æ ˆè·Ÿè¸ª: $stackTrace');
      return TextExtractionResult(
        text: '',
        error: 'PDFæ–‡ä»¶è¯»å–å¤±è´¥: $eã€‚å»ºè®®ä½¿ç”¨æ–‡æœ¬ç‰ˆPDFè€Œéæ‰«æç‰ˆPDFã€‚',
      );
    }
  }

  /// æå–DOCXæ–‡æœ¬å†…å®¹
  Future<TextExtractionResult> _extractDocxText(String filePath) async {
    try {
      debugPrint('ğŸ“„ å¼€å§‹å¤„ç†DOCXæ–‡ä»¶: $filePath');
      final file = File(filePath);

      if (!await file.exists()) {
        return const TextExtractionResult(text: '', error: 'DOCXæ–‡ä»¶ä¸å­˜åœ¨');
      }

      final bytes = await file.readAsBytes();
      debugPrint('ğŸ“Š DOCXæ–‡ä»¶å¤§å°: ${bytes.length} bytes');

      // ä½¿ç”¨ZipDecoderè§£æDOCXæ–‡ä»¶ç»“æ„
      final archive = ZipDecoder().decodeBytes(bytes);
      final docxContent = StringBuffer();
      bool foundDocument = false;

      // æŸ¥æ‰¾ word/document.xml æ–‡ä»¶
      for (final archiveFile in archive) {
        if (archiveFile.name == 'word/document.xml') {
          foundDocument = true;
          debugPrint('âœ… æ‰¾åˆ°document.xmlæ–‡ä»¶');

          try {
            final xmlContent = archiveFile.content as List<int>;
            final xmlString = utf8.decode(xmlContent);
            final xmlDoc = XmlDocument.parse(xmlString);

            // æå–æ‰€æœ‰æ–‡æœ¬èŠ‚ç‚¹
            final textNodes = xmlDoc.findAllElements('w:t');
            debugPrint('ğŸ“ æ‰¾åˆ°${textNodes.length}ä¸ªæ–‡æœ¬èŠ‚ç‚¹');

            for (final textNode in textNodes) {
              final text = textNode.innerText;
              if (text.isNotEmpty) {
                docxContent.write(text);
                docxContent.write(' '); // æ·»åŠ ç©ºæ ¼åˆ†éš”
              }
            }
            break;
          } catch (xmlError) {
            debugPrint('âŒ XMLè§£æé”™è¯¯: $xmlError');
            return TextExtractionResult(
              text: '',
              error: 'DOCXæ–‡ä»¶XMLè§£æå¤±è´¥: $xmlError',
            );
          }
        }
      }

      if (!foundDocument) {
        return const TextExtractionResult(
          text: '',
          error: 'DOCXæ–‡ä»¶æ ¼å¼æ— æ•ˆï¼šæœªæ‰¾åˆ°document.xml',
        );
      }

      final extractedText = docxContent.toString().trim();
      debugPrint('âœ… DOCXæ–‡æœ¬æå–å®Œæˆï¼Œé•¿åº¦: ${extractedText.length}');

      if (extractedText.isEmpty) {
        return const TextExtractionResult(text: '', error: 'DOCXæ–‡ä»¶ä¸­æœªæ‰¾åˆ°æ–‡æœ¬å†…å®¹');
      }

      return TextExtractionResult(text: extractedText);
    } catch (e, stackTrace) {
      debugPrint('ğŸ’¥ DOCXæ–‡ä»¶å¤„ç†å¼‚å¸¸: $e');
      debugPrint('å †æ ˆè·Ÿè¸ª: $stackTrace');
      return TextExtractionResult(text: '', error: 'DOCXæ–‡ä»¶è¯»å–å¤±è´¥: $e');
    }
  }

  /// æå–RTFæ–‡æœ¬å†…å®¹
  Future<TextExtractionResult> _extractRtfText(String filePath) async {
    try {
      final file = File(filePath);
      final content = await file.readAsString(encoding: utf8);

      // ç®€å•çš„RTFè§£æï¼šå»é™¤æ§åˆ¶ç¬¦ï¼Œæå–çº¯æ–‡æœ¬
      final textBuffer = StringBuffer();
      bool inControlWord = false;

      for (int i = 0; i < content.length; i++) {
        final char = content[i];

        if (char == '{' || char == '}') {
          // è·³è¿‡ç»„åˆ†éš”ç¬¦
          continue;
        } else if (char == '\\') {
          inControlWord = true;
          continue;
        } else if (inControlWord) {
          if (char == ' ' || char == '\n' || char == '\r') {
            inControlWord = false;
          }
          continue;
        }

        // å¦‚æœä¸åœ¨æ§åˆ¶å­—ç¬¦ä¸­ï¼Œæ·»åŠ åˆ°æ–‡æœ¬ä¸­
        if (!inControlWord && char.codeUnitAt(0) >= 32) {
          textBuffer.write(char);
        }
      }

      return TextExtractionResult(text: textBuffer.toString().trim());
    } catch (e) {
      return TextExtractionResult(text: '', error: 'RTFæ–‡ä»¶è¯»å–å¤±è´¥: $e');
    }
  }

  /// æå–PPTXæ–‡æœ¬å†…å®¹
  Future<TextExtractionResult> _extractPptxText(String filePath) async {
    try {
      debugPrint('ğŸ“„ å¼€å§‹å¤„ç†PPTXæ–‡ä»¶: $filePath');
      final file = File(filePath);

      if (!await file.exists()) {
        return const TextExtractionResult(text: '', error: 'PPTXæ–‡ä»¶ä¸å­˜åœ¨');
      }

      final bytes = await file.readAsBytes();
      debugPrint('ğŸ“Š PPTXæ–‡ä»¶å¤§å°: ${bytes.length} bytes');

      // ä½¿ç”¨ZipDecoderè§£æPPTXæ–‡ä»¶ç»“æ„
      final archive = ZipDecoder().decodeBytes(bytes);
      final pptxContent = StringBuffer();
      int slideCount = 0;

      // æŸ¥æ‰¾æ‰€æœ‰å¹»ç¯ç‰‡æ–‡ä»¶
      for (final archiveFile in archive) {
        if (archiveFile.name.startsWith('ppt/slides/slide') &&
            archiveFile.name.endsWith('.xml')) {
          slideCount++;

          try {
            final xmlContent = archiveFile.content as List<int>;
            final xmlString = utf8.decode(xmlContent);
            final xmlDoc = XmlDocument.parse(xmlString);

            // æå–æ‰€æœ‰æ–‡æœ¬èŠ‚ç‚¹
            final textNodes = xmlDoc.findAllElements('a:t');

            if (textNodes.isNotEmpty) {
              pptxContent.writeln('\n=== å¹»ç¯ç‰‡ $slideCount ===');
              for (final textNode in textNodes) {
                final text = textNode.innerText.trim();
                if (text.isNotEmpty) {
                  pptxContent.writeln(text);
                }
              }
            }
          } catch (xmlError) {
            debugPrint('âŒ å¹»ç¯ç‰‡ $slideCount XMLè§£æé”™è¯¯: $xmlError');
            continue;
          }
        }
      }

      final extractedText = pptxContent.toString().trim();
      debugPrint(
        'âœ… PPTXæ–‡æœ¬æå–å®Œæˆï¼Œå¤„ç†äº† $slideCount å¼ å¹»ç¯ç‰‡ï¼Œé•¿åº¦: ${extractedText.length}',
      );

      if (extractedText.isEmpty) {
        return const TextExtractionResult(text: '', error: 'PPTXæ–‡ä»¶ä¸­æœªæ‰¾åˆ°æ–‡æœ¬å†…å®¹');
      }

      return TextExtractionResult(text: extractedText);
    } catch (e, stackTrace) {
      debugPrint('ğŸ’¥ PPTXæ–‡ä»¶å¤„ç†å¼‚å¸¸: $e');
      debugPrint('å †æ ˆè·Ÿè¸ª: $stackTrace');
      return TextExtractionResult(text: '', error: 'PPTXæ–‡ä»¶è¯»å–å¤±è´¥: $e');
    }
  }

  /// æå–XLSXæ–‡æœ¬å†…å®¹
  Future<TextExtractionResult> _extractXlsxText(String filePath) async {
    try {
      debugPrint('ğŸ“„ å¼€å§‹å¤„ç†XLSXæ–‡ä»¶: $filePath');
      final file = File(filePath);

      if (!await file.exists()) {
        return const TextExtractionResult(text: '', error: 'XLSXæ–‡ä»¶ä¸å­˜åœ¨');
      }

      final bytes = await file.readAsBytes();
      debugPrint('ğŸ“Š XLSXæ–‡ä»¶å¤§å°: ${bytes.length} bytes');

      // ä½¿ç”¨ZipDecoderè§£æXLSXæ–‡ä»¶ç»“æ„
      final archive = ZipDecoder().decodeBytes(bytes);
      final xlsxContent = StringBuffer();

      // æŸ¥æ‰¾å…±äº«å­—ç¬¦ä¸²è¡¨
      Map<int, String> sharedStrings = {};
      for (final archiveFile in archive) {
        if (archiveFile.name == 'xl/sharedStrings.xml') {
          try {
            final xmlContent = archiveFile.content as List<int>;
            final xmlString = utf8.decode(xmlContent);
            final xmlDoc = XmlDocument.parse(xmlString);

            final stringItems = xmlDoc.findAllElements('si');
            int index = 0;
            for (final item in stringItems) {
              final textNodes = item.findAllElements('t');
              final text = textNodes.map((node) => node.innerText).join('');
              sharedStrings[index] = text;
              index++;
            }
          } catch (e) {
            debugPrint('âŒ å…±äº«å­—ç¬¦ä¸²è§£æé”™è¯¯: $e');
          }
          break;
        }
      }

      // æŸ¥æ‰¾å·¥ä½œè¡¨æ–‡ä»¶
      int sheetCount = 0;
      for (final archiveFile in archive) {
        if (archiveFile.name.startsWith('xl/worksheets/sheet') &&
            archiveFile.name.endsWith('.xml')) {
          sheetCount++;

          try {
            final xmlContent = archiveFile.content as List<int>;
            final xmlString = utf8.decode(xmlContent);
            final xmlDoc = XmlDocument.parse(xmlString);

            xlsxContent.writeln('\n=== å·¥ä½œè¡¨ $sheetCount ===');

            // æå–æ‰€æœ‰å•å…ƒæ ¼
            final cells = xmlDoc.findAllElements('c');
            for (final cell in cells) {
              final valueElement = cell.findElements('v').firstOrNull;
              if (valueElement != null) {
                final value = valueElement.innerText;
                final cellType = cell.getAttribute('t');

                String cellText = value;
                if (cellType == 's') {
                  // å…±äº«å­—ç¬¦ä¸²å¼•ç”¨
                  final index = int.tryParse(value);
                  if (index != null && sharedStrings.containsKey(index)) {
                    cellText = sharedStrings[index]!;
                  }
                }

                if (cellText.trim().isNotEmpty) {
                  xlsxContent.writeln(cellText);
                }
              }
            }
          } catch (xmlError) {
            debugPrint('âŒ å·¥ä½œè¡¨ $sheetCount XMLè§£æé”™è¯¯: $xmlError');
            continue;
          }
        }
      }

      final extractedText = xlsxContent.toString().trim();
      debugPrint(
        'âœ… XLSXæ–‡æœ¬æå–å®Œæˆï¼Œå¤„ç†äº† $sheetCount ä¸ªå·¥ä½œè¡¨ï¼Œé•¿åº¦: ${extractedText.length}',
      );

      if (extractedText.isEmpty) {
        return const TextExtractionResult(text: '', error: 'XLSXæ–‡ä»¶ä¸­æœªæ‰¾åˆ°æ–‡æœ¬å†…å®¹');
      }

      return TextExtractionResult(text: extractedText);
    } catch (e, stackTrace) {
      debugPrint('ğŸ’¥ XLSXæ–‡ä»¶å¤„ç†å¼‚å¸¸: $e');
      debugPrint('å †æ ˆè·Ÿè¸ª: $stackTrace');
      return TextExtractionResult(text: '', error: 'XLSXæ–‡ä»¶è¯»å–å¤±è´¥: $e');
    }
  }

  /// æå–CSVæ–‡æœ¬å†…å®¹
  Future<TextExtractionResult> _extractCsvText(String filePath) async {
    try {
      final file = File(filePath);
      final content = await file.readAsString(encoding: utf8);

      // ç®€å•çš„CSVè§£æï¼Œå°†é€—å·åˆ†éš”çš„å†…å®¹è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬
      final lines = content.split('\n');
      final csvContent = StringBuffer();

      for (int i = 0; i < lines.length; i++) {
        final line = lines[i].trim();
        if (line.isNotEmpty) {
          // å°†CSVè¡Œè½¬æ¢ä¸ºæ›´å¯è¯»çš„æ ¼å¼
          final cells = line
              .split(',')
              .map((cell) => cell.trim().replaceAll('"', ''))
              .toList();
          if (i == 0) {
            csvContent.writeln('=== è¡¨å¤´ ===');
          }
          csvContent.writeln(cells.join(' | '));
        }
      }

      return TextExtractionResult(text: csvContent.toString().trim());
    } catch (e) {
      return TextExtractionResult(text: '', error: 'CSVæ–‡ä»¶è¯»å–å¤±è´¥: $e');
    }
  }

  /// æå–JSONæ–‡æœ¬å†…å®¹
  Future<TextExtractionResult> _extractJsonText(String filePath) async {
    try {
      final file = File(filePath);
      final content = await file.readAsString(encoding: utf8);

      // å°è¯•è§£æJSONå¹¶æå–æ–‡æœ¬å†…å®¹
      final jsonContent = StringBuffer();

      try {
        final jsonData = json.decode(content);
        _extractJsonValues(jsonData, jsonContent, 0);
      } catch (jsonError) {
        // å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹
        return TextExtractionResult(text: content);
      }

      return TextExtractionResult(text: jsonContent.toString().trim());
    } catch (e) {
      return TextExtractionResult(text: '', error: 'JSONæ–‡ä»¶è¯»å–å¤±è´¥: $e');
    }
  }

  /// é€’å½’æå–JSONå€¼
  void _extractJsonValues(dynamic data, StringBuffer buffer, int depth) {
    final indent = '  ' * depth;

    if (data is Map) {
      for (final entry in data.entries) {
        buffer.writeln('$indent${entry.key}:');
        _extractJsonValues(entry.value, buffer, depth + 1);
      }
    } else if (data is List) {
      for (int i = 0; i < data.length; i++) {
        buffer.writeln('$indent[$i]:');
        _extractJsonValues(data[i], buffer, depth + 1);
      }
    } else {
      buffer.writeln('$indent$data');
    }
  }

  /// æå–XMLæ–‡æœ¬å†…å®¹
  Future<TextExtractionResult> _extractXmlText(String filePath) async {
    try {
      final file = File(filePath);
      final content = await file.readAsString(encoding: utf8);

      try {
        final xmlDoc = XmlDocument.parse(content);
        final xmlContent = StringBuffer();

        // é€’å½’æå–æ‰€æœ‰æ–‡æœ¬èŠ‚ç‚¹
        _extractXmlTextNodes(xmlDoc.rootElement, xmlContent, 0);

        return TextExtractionResult(text: xmlContent.toString().trim());
      } catch (xmlError) {
        // å¦‚æœXMLè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹
        return TextExtractionResult(text: content);
      }
    } catch (e) {
      return TextExtractionResult(text: '', error: 'XMLæ–‡ä»¶è¯»å–å¤±è´¥: $e');
    }
  }

  /// é€’å½’æå–XMLæ–‡æœ¬èŠ‚ç‚¹
  void _extractXmlTextNodes(
    XmlElement element,
    StringBuffer buffer,
    int depth,
  ) {
    final indent = '  ' * depth;

    // æ·»åŠ å…ƒç´ åç§°
    buffer.writeln('$indent${element.name}:');

    // æå–æ–‡æœ¬å†…å®¹
    final text = element.innerText.trim();
    if (text.isNotEmpty &&
        element.children.every((child) => child is XmlText)) {
      buffer.writeln('$indent  $text');
    }

    // é€’å½’å¤„ç†å­å…ƒç´ 
    for (final child in element.children) {
      if (child is XmlElement) {
        _extractXmlTextNodes(child, buffer, depth + 1);
      }
    }
  }

  /// æå–HTMLæ–‡æœ¬å†…å®¹
  Future<TextExtractionResult> _extractHtmlText(String filePath) async {
    try {
      final file = File(filePath);
      final content = await file.readAsString(encoding: utf8);

      // ç®€å•çš„HTMLæ ‡ç­¾ç§»é™¤
      String cleanText = content
          .replaceAll(
            RegExp(
              r'<script[^>]*>.*?</script>',
              caseSensitive: false,
              dotAll: true,
            ),
            '',
          )
          .replaceAll(
            RegExp(
              r'<style[^>]*>.*?</style>',
              caseSensitive: false,
              dotAll: true,
            ),
            '',
          )
          .replaceAll(RegExp(r'<[^>]+>'), ' ')
          .replaceAll(RegExp(r'\s+'), ' ')
          .trim();

      return TextExtractionResult(text: cleanText);
    } catch (e) {
      return TextExtractionResult(text: '', error: 'HTMLæ–‡ä»¶è¯»å–å¤±è´¥: $e');
    }
  }
}
